# ğŸ¬ Context-Aware Emotion Detection from Subtitle Text

A web application that detects emotions in subtitle (`.srt`) files using a fine-tuned NLP transformer model and generates **color-coded subtitles** for VLC Media Player.

> **Final Year Engineering Project**

---

## âœ¨ Features

- **Upload & Analyze** â€” Drag-and-drop `.srt` files for instant emotion analysis
- **Fine-Tuned Model** â€” RoBERTa model fine-tuned on the MELD (Friends TV show) dataset for 7 emotions
- **Context-Aware** â€” Majority-vote aggregation across neighbouring subtitles stabilizes predictions
- **Color-Coded Output** â€” Download emotion-colored `.srt` files playable in VLC
- **CPU-Only** â€” Runs on any machine without a GPU

## ğŸ­ Supported Emotions

| Emotion | Color |
|---------|-------|
| Joy | ğŸŸ¢ Green |
| Sadness | ğŸ”µ Blue |
| Anger | ğŸ”´ Red |
| Fear | ğŸŸ£ Purple |
| Surprise | ğŸŸ¡ Yellow |
| Disgust | ğŸŸ¤ Brown |
| Neutral | âšª White |

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- pip

### 1. Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/subtitle-emotion-detection.git
cd subtitle-emotion-detection
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Download the Fine-Tuned Model

The fine-tuned model (~500 MB) is too large for GitHub. Download it from:

> ğŸ“¥ **[Download Link â€” Google Drive / Hugging Face]** *(add your link here)*

After downloading, place the model files in a `finetuned_model/` folder in the project root:

```
project-root/
â”œâ”€â”€ finetuned_model/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ training_args.bin
â”œâ”€â”€ app.py
â””â”€â”€ ...
```

### 4. Run the Application

```bash
python app.py
```

Open **http://localhost:5000** in your browser.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app.py                  # Flask web server & API routes
â”œâ”€â”€ emotion_model.py        # Emotion classification (HuggingFace pipeline)
â”œâ”€â”€ srt_utils.py            # SRT parsing, context windows & colored output
â”œâ”€â”€ finetune.py             # Fine-tuning script (RoBERTa on MELD)
â”œâ”€â”€ prepare_meld.py         # MELD dataset download & preparation
â”œâ”€â”€ compare_models.py       # Base vs fine-tuned model comparison
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ sample.srt              # Sample subtitle file for testing
â”œâ”€â”€ demo.srt                # Demo subtitle file
â”œâ”€â”€ PROJECT_PROGRESS.md     # Detailed development log
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Main UI page
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css           # Dark theme with glassmorphism
â”‚   â””â”€â”€ script.js           # Upload logic, animations & results
â”œâ”€â”€ uploads/                # (auto-created) temporary uploads
â””â”€â”€ outputs/                # (auto-created) color-coded SRT outputs
```

---

## âš™ï¸ How It Works

```
Upload .srt â†’ Parse Subtitles â†’ Classify Each Line â†’ Apply Threshold â†’ Majority-Vote Aggregation â†’ Color-Coded .srt
```

1. **Parse** â€” Extract subtitle entries from the `.srt` file
2. **Classify** â€” Run each subtitle line through the fine-tuned RoBERTa model
3. **Threshold** â€” Replace low-confidence predictions (<0.25) with "neutral"
4. **Aggregate** â€” Majority-vote across a sliding window (Â±2 neighbours) for context-aware stabilization
5. **Output** â€” Generate a color-coded `.srt` file with `<font color>` tags compatible with VLC

---

## ğŸ› ï¸ Technology Stack

| Component | Technology |
|-----------|------------|
| Backend | Python 3 + Flask |
| NLP Model | RoBERTa (GoEmotions â†’ fine-tuned on MELD) |
| ML Framework | PyTorch (CPU-only) |
| Transformers | HuggingFace Transformers |
| Frontend | HTML5 + CSS3 + JavaScript |
| UI Design | Dark theme, glassmorphism, Bootstrap 5 |
| Subtitle Format | SRT with VLC `<font color>` tags |

---

## ğŸ”¬ Fine-Tuning Details

- **Base Model:** `SamLowe/roberta-base-go_emotions` (28-class Reddit emotions)
- **Dataset:** MELD (Multimodal EmotionLines Dataset â€” Friends TV show, ~9,800 dialogues)
- **Training:** 4 epochs, lr=2e-5, batch size 16
- **Result:** 60.2% accuracy / 0.59 F1 (vs ~14% random chance for 7 classes)

To re-run fine-tuning:

```bash
python prepare_meld.py      # Download & prepare MELD dataset
python finetune.py           # Fine-tune the model (GPU recommended)
```

---

## ğŸ“ API Endpoints

| Route | Method | Description |
|-------|--------|-------------|
| `/` | GET | Serve the main web UI |
| `/upload` | POST | Upload `.srt` file, returns emotion analysis as JSON |
| `/download/<filename>` | GET | Download the color-coded `.srt` file |

---

## âš ï¸ Disclaimer

This tool is intended for **academic and research purposes only**. It is not a substitute for professional psychological or clinical assessment. Emotion detection from text has inherent limitations and should not be used for diagnostic purposes.

---

## ğŸ“„ License

This project was developed as a Final Year Engineering Project.
